{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#выгружаем-датасет:\" data-toc-modified-id=\"выгружаем-датасет:-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>выгружаем датасет:</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8Xnjf9hMQ2t"
   },
   "source": [
    "Задание 1: Реализовать Bag of words & tfidf на jokes.csv (в архиве)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZT1jfI2Iwo5S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.9/site-packages (3.8.1)\n",
      "Requirement already satisfied: gensim in /opt/anaconda3/lib/python3.9/site-packages (4.3.1)\n",
      "Requirement already satisfied: bokeh in /opt/anaconda3/lib/python3.9/site-packages (2.4.3)\n",
      "Collecting bokeh\n",
      "  Using cached bokeh-3.1.0-py3-none-any.whl (8.3 MB)\n",
      "Requirement already satisfied: umap-learn in /opt/anaconda3/lib/python3.9/site-packages (0.5.3)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/anaconda3/lib/python3.9/site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.22.4)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /opt/anaconda3/lib/python3.9/site-packages (from bokeh) (6.0)\n",
      "Requirement already satisfied: contourpy>=1 in /opt/anaconda3/lib/python3.9/site-packages (from bokeh) (1.0.7)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /opt/anaconda3/lib/python3.9/site-packages (from bokeh) (2023.2.0)\n",
      "Requirement already satisfied: tornado>=5.1 in /opt/anaconda3/lib/python3.9/site-packages (from bokeh) (6.2)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /opt/anaconda3/lib/python3.9/site-packages (from bokeh) (9.4.0)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /opt/anaconda3/lib/python3.9/site-packages (from bokeh) (3.1.2)\n",
      "Requirement already satisfied: packaging>=16.8 in /opt/anaconda3/lib/python3.9/site-packages (from bokeh) (23.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/anaconda3/lib/python3.9/site-packages (from bokeh) (1.5.3)\n",
      "Requirement already satisfied: numba>=0.49 in /opt/anaconda3/lib/python3.9/site-packages (from umap-learn) (0.56.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /opt/anaconda3/lib/python3.9/site-packages (from umap-learn) (0.24.2)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /opt/anaconda3/lib/python3.9/site-packages (from umap-learn) (0.5.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.9/site-packages (from Jinja2>=2.9->bokeh) (2.1.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/anaconda3/lib/python3.9/site-packages (from numba>=0.49->umap-learn) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.9/site-packages (from numba>=0.49->umap-learn) (65.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.2->bokeh) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.2->bokeh) (2022.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.22->umap-learn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.2->bokeh) (1.16.0)\n",
      "Installing collected packages: bokeh\n",
      "  Attempting uninstall: bokeh\n",
      "    Found existing installation: bokeh 2.4.3\n",
      "    Uninstalling bokeh-2.4.3:\n",
      "      Successfully uninstalled bokeh-2.4.3\n",
      "Successfully installed bokeh-3.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/vasilijpancenko/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/vasilijpancenko/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade nltk gensim bokeh umap-learn\n",
    "\n",
    "import itertools\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import umap\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kO9YqXRGanBA"
   },
   "source": [
    "Готовые модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HoGzaVSkaccC",
    "outputId": "68ff956c-82f5-4449-a09c-1cf0d55e04b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('realtor', 0.8265186548233032),\n",
       " ('gfx', 0.8249695897102356),\n",
       " ('caterers', 0.798202395439148),\n",
       " ('beatmaker', 0.7936854362487793),\n",
       " ('recruiter', 0.7892400026321411),\n",
       " ('sfi', 0.784467339515686),\n",
       " ('sosh', 0.7840632796287537),\n",
       " ('promoter', 0.7838250994682312),\n",
       " ('smallbusiness', 0.7786215543746948),\n",
       " ('promoters', 0.77646803855896)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import gensim\n",
    "import gensim.downloader as api \n",
    "model = api.load('glove-twitter-25') \n",
    "model.most_similar(positive=[\"coder\", \"money\"], negative=[\"brain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1RKyzcmdcPM",
    "outputId": "f6a68480-1687-46c8-db9c-8c60e0d2efd1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/vasilijpancenko/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vasilijpancenko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "scrapped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Artificial_intelligence')\n",
    "article = scrapped_data.read()\n",
    "\n",
    "parsed_article = bs.BeautifulSoup(article,'lxml')\n",
    "\n",
    "paragraphs = parsed_article.find_all('p')\n",
    "\n",
    "article_text = \"\"\n",
    "\n",
    "for p in paragraphs:\n",
    "    article_text += p.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6LpxidXcddU6"
   },
   "outputs": [],
   "source": [
    "# Cleaing the text\n",
    "processed_article = article_text.lower()\n",
    "processed_article = re.sub('[^a-zA-Z]', ' ', processed_article )\n",
    "processed_article = re.sub(r'\\s+', ' ', processed_article)\n",
    "\n",
    "# Preparing the dataset\n",
    "all_sentences = nltk.sent_tokenize(processed_article)\n",
    "\n",
    "all_words = [nltk.word_tokenize(sent) for sent in all_sentences]\n",
    "\n",
    "# Removing Stop Words\n",
    "from nltk.corpus import stopwords\n",
    "for i in range(len(all_words)):\n",
    "    all_words[i] = [w for w in all_words[i] if w not in stopwords.words('english')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DDI2eJNmdiKD"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "word2vec = Word2Vec(all_words, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Rr5pjuAdmtz",
    "outputId": "3a01f86a-1d97-47e0-fb60-70035ca45ed8"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vocabulary \u001b[38;5;241m=\u001b[39m \u001b[43mword2vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(vocabulary)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py:734\u001b[0m, in \u001b[0;36mKeyedVectors.vocab\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvocab\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 734\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    735\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe vocab attribute was removed from KeyedVector in Gensim 4.0.0.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    736\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse KeyedVector\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms .key_to_index dict, .index_to_key list, and methods \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    737\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    738\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    739\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4"
     ]
    }
   ],
   "source": [
    "vocabulary = word2vec.wv.vocab\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4rXdOgcQdqfn"
   },
   "outputs": [],
   "source": [
    "v1 = word2vec.wv['artificial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4KuHGRB7dvfU",
    "outputId": "ef534bda-2281-4def-a99f-db4c5ed9ce2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('training', 0.40299665927886963),\n",
       " ('ai', 0.37336066365242004),\n",
       " ('general', 0.36903053522109985),\n",
       " ('would', 0.35330915451049805),\n",
       " ('model', 0.33899199962615967),\n",
       " ('systems', 0.33775126934051514),\n",
       " ('approaches', 0.3296746611595154),\n",
       " ('also', 0.3175889551639557),\n",
       " ('machine', 0.313571959733963),\n",
       " ('easy', 0.30880311131477356)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_words = word2vec.wv.most_similar('intelligence')\n",
    "sim_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NtaXKgMKtseD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YSDFpWXfChU"
   },
   "source": [
    "Задание 2: на базе датасета обучить модель \n",
    "\n",
    "# выгружаем датасет:\n",
    "!wget https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1 -O ./quora.txt -nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKBGekA0fGFZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
